= Automated Multilingual Evaluation Pipeline (AMEP)
:navtitle: Home
:description: A modular framework for evaluating LLMs on OpenShift AI 3.0.
:keywords: openshift ai, rhoai, llm, evaluation, trustyai, model registry, vllm

[.lead]
A deployable, modular solution framework for Platform Engineers to package, deploy, and evaluate Large Language Models (LLMs) on Red Hat OpenShift AI 3.0.

== ğŸ‘‹ Welcome

Welcome to the **Automated Multilingual Evaluation Pipeline (AMEP)** solution kit.

If you are a **Platform Engineer**, you know the struggle: your AI Developers and Data Scientists want to use the "latest and greatest" open-source models, but they need to know if those models actually work for your specific business requirementsâ€”especially when supporting multiple languages.

This solution is designed to help you solve the "Paradox of Choice." It provides the architectural plumbing to turn ad-hoc model guessing into a standardized engineering process.

[NOTE]
.A Modular Framework
====
This solution is broken down into **four distinct, manual phases**. This design allows you to understand exactly how the components interact, debug easily, and reuse individual modules in your own custom workflows.
====

== ğŸ¯ Who Is This For?

We built this specifically for the people building atoken generation platform used to build Gen AI powered applications:

* **Platform Engineers (Primary):** You need to provide a robust service to your Gen AI development teams. This guide shows you how to build the infrastructure for model evaluation.
* **Service Consultants:** You are delivering OpenShift AI solutions to customers. Use this kit as a reference architecture or a base for your delivery engagements.
* **Red Hat Partners:** You are building integrations on top of OpenShift AI 3.0. This framework demonstrates practices for using RHOAI Model Registry, Packaging Models in ModelCar, and using TrustyAI LM_Eval integration.

== ğŸ§© The Solution Framework

The solution is divided into four sequential phases. You can run them in order to build the full pipeline, or use them independently.

=== Phase 1: Package & Register ğŸ“¦
**"Treat Models Like Software"** +
Stop downloading weights at runtime. We show you how to package an LLM into an OCI container image (a "ModelCar") using `podman`. You will then register this artifact in the **OpenShift AI Model Registry** for governance and versioning.

=== Phase 2: Deploy (vLLM) ğŸš€
**"High-Performance Serving"** +
Manually trigger the deployment of your registered model using **vLLM**, the state-of-the-art inference engine. You will configure the `ServingRuntime` and ensure GPU resources are allocated correctly.

=== Phase 3: Evaluate (TrustyAI) âš–ï¸
**"The Test Drive"** +
Deploy a **TrustyAI LMEval_Job**â€”a Kubernetes Custom Resource that automatically runs standardized fluency tests against your deployed model.
* **Languages Tested:** English ğŸ‡ºğŸ‡¸, Spanish ğŸ‡ªğŸ‡¸, Japanese ğŸ‡¯ğŸ‡µ
* **Metrics:** Accuracy, Fluency, and Hallucination resistance.

=== Phase 4: Visualize ğŸ“Š
**"Make It Visible"** +
Gather raw JSON data from object storage (S3) and use a Jupyter Notebook to generate a **Radar Chart**. This provides a clean visual artifact to show stakeholders exactly how different models compare.

== ğŸ› ï¸ Tech Stack

This solution utilizes standard, cloud-native components available in OpenShift AI 3.0:

[cols="1,3"]
|===
|Component | Role

|**Model Registry**
|Central catalog for tracking ModelCar versions and metadata.

|**vLLM**
|High-performance inference engine (via KServe) for serving models.

|**TrustyAI**
|Executes the `lm-evaluation-harness` to metricize performance.

|**S3 Storage**
|Stores evaluation datasets and resulting metrics (ODF/MinIO).

|**Jupyter**
|Provides the interactive dashboard for result analysis.
|===

== ğŸš€ Prerequisites

Before starting Phase 1, ensure you have the following:

* [ ] Access to an **OpenShift AI 3.0+** cluster.
* [ ] **Cluster Admin** privileges (required for setting up initial ServingRuntimes).
* [ ] **S3 Storage** credentials (bucket name, endpoint, access key, secret key).
* [ ] A **Container Registry** (Quay.io or internal) to push your ModelCar images.

== Let's Get Started

Ready to build the foundation?

* xref:phase-1:index.adoc[Start with Phase 1: Package & Register]